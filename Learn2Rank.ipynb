{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0214a34b",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c748d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18d6572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"./data/corpus.tsv\", delimiter=\"\\t\", names=[\"qid\",\"query\"])\n",
    "queries = pd.read_csv(\"./data/queries.tsv\", delimiter=\"\\t\", names=[\"qid\",\"query\"])\n",
    "\n",
    "qrels_test = pd.read_csv(\"./data/qrels.test.tsv\", delimiter=\"\\t\", names=[\"qid\",\"q0\",\"docid\",\"label\"]).drop(columns=\"q0\")\n",
    "qrels_train = pd.read_csv(\"./data/qrels.train.tsv\", delimiter=\"\\t\", names=[\"qid\",\"q0\",\"docid\",\"label\"]).drop(columns=\"q0\")\n",
    "\n",
    "topics_test = pd.read_csv(\"./data/topics.test.tsv\", delimiter=\"\\t\", names=[\"qid\",\"query\"])\n",
    "topics_train = pd.read_csv(\"./data/topics.train.tsv\", delimiter=\"\\t\", names=[\"qid\",\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "83f4f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_train[\"query\"] = topics_train[\"query\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84f1e2",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trec_generator(filepath, delim, verbose=False):\n",
    "    file = open(filepath)\n",
    "    file_reader = csv.reader(file, delimiter=delim)\n",
    "    \n",
    "    UP = \"\\x1B[3A\"\n",
    "    CLR = \"\\x1B[0K\"\n",
    "    print(\"\\n\\n\")  # set up blank lines so cursor moves work\n",
    "    for i, (docno, text) in enumerate(file_reader):\n",
    "        if i % 100000 == 0 and verbose:\n",
    "            print(f'{UP}Generated {i}{CLR}\\n')\n",
    "        yield {'docno': docno, 'text': text}\n",
    "\n",
    "\n",
    "def create_index():\n",
    "    start = time.time()\n",
    "    index_path = \"./index\"\n",
    "    indexer = pt.IterDictIndexer(index_path, verbose=True, overwrite=True)\n",
    "    trec_iter = trec_generator(\"./data/collection.tsv\", '\\t', verbose=True)\n",
    "    indexref = indexer.index(trec_iter)\n",
    "    end = time.time()\n",
    "    print(\"Indexing took: \", str(end - start))\n",
    "\n",
    "# Start indexing (takes 7 minutes)\n",
    "# create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(\"./index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237ed85",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624ed068",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bm25 \u001b[38;5;241m=\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241m.\u001b[39mBatchRetrieve(index, wmodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25\u001b[39m\u001b[38;5;124m\"\u001b[39m, controls\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbm25.k_1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbm25.b\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.4\u001b[39m}, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mBatchRetrieve(index, wmodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF_IDF\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m bm25 \u001b[38;5;241m>>\u001b[39m tfidf\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pt' is not defined"
     ]
    }
   ],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls={\"bm25.k_1\": 0.9, \"bm25.b\": 0.4}, verbose=True)\n",
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\", verbose=True)\n",
    "\n",
    "pipeline = bm25 >> tfidf\n",
    "df = pipeline.transform(topics_train_pyterrier)\n",
    "# Our algorithm did not manage to run beyond this point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2r",
   "language": "python",
   "name": "l2r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
